{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does a 5 layer neural network on the data in cleaned_spotify.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Obtaining dependency information for pytorch-lightning from https://files.pythonhosted.org/packages/2b/d2/ecd65ff1e0b1ca79f9785dd65d5ced7ec2643a828068aaa24e47e4c84a14/pytorch_lightning-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torch>=2.1.0 (from pytorch-lightning)\n",
      "  Obtaining dependency information for torch>=2.1.0 from https://files.pythonhosted.org/packages/5f/ba/607d013b55b9fd805db2a5c2662ec7551f1910b4eef39653eeaba182c5b2/torch-2.5.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting tqdm>=4.57.0 (from pytorch-lightning)\n",
      "  Obtaining dependency information for tqdm>=4.57.0 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from pytorch-lightning) (6.0.2)\n",
      "Collecting fsspec[http]>=2022.5.0 (from pytorch-lightning)\n",
      "  Obtaining dependency information for fsspec[http]>=2022.5.0 from https://files.pythonhosted.org/packages/c6/b2/454d6e7f0158951d8a78c2e1eb4f69ae81beb8dca5fee9809c6c99e9d0d0/fsspec-2024.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Obtaining dependency information for torchmetrics>=0.7.0 from https://files.pythonhosted.org/packages/46/1a/9728a502f377ab8cff1fd15c625aa2919a183fa113ebcefa2cd38edff28b/torchmetrics-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from pytorch-lightning) (24.1)\n",
      "Collecting typing-extensions>=4.4.0 (from pytorch-lightning)\n",
      "  Obtaining dependency information for typing-extensions>=4.4.0 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Obtaining dependency information for lightning-utilities>=0.10.0 from https://files.pythonhosted.org/packages/85/f3/1305321a12c984405e26fc64b5d521569e9872fb811f4aace8e168099160/lightning_utilities-0.11.9-py3-none-any.whl.metadata\n",
      "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for aiohttp!=4.0.0a0,!=4.0.0a1 from https://files.pythonhosted.org/packages/3a/51/df9c263c861ce93998b5ad2ba3212caab2112d5b66dbe91ddbe90c41ded4/aiohttp-3.11.10-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.11.10-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
      "Collecting filelock (from torch>=2.1.0->pytorch-lightning)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/b9/f8/feced7779d755758a52d1f6635d990b8d98dc0a29fa568bbe0625f18fdf3/filelock-3.16.1-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch>=2.1.0->pytorch-lightning)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
      "Collecting sympy==1.13.1 (from torch>=2.1.0->pytorch-lightning)\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.3.0 from https://files.pythonhosted.org/packages/b9/74/fbb6559de3607b3300b9be3cc64e97548d55678e44623db17820dbd20002/aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b1/56/4e45136ffc6bdbfa68c29ca56ef53783ef4c2fd395f7cbf99a2624aa9aaa/frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/a3/bf/f332a13486b1ed0496d624bcc7e8357bb8053823e8cd4b9a18edc1d97e73/multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/3b/77/a92c3ef994e47180862b9d7d11e37624fb1c00a16d61faf55115d970628b/propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/34/45/0e055320daaabfc169b21ff6174567b2c910c45617b0d79c68d7ab349b02/yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\zane clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
      "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "   ---------------------------------------- 0.0/815.2 kB ? eta -:--:--\n",
      "   ---------------------------------- ---- 716.8/815.2 kB 15.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 815.2/815.2 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.4/203.0 MB 8.9 MB/s eta 0:00:23\n",
      "   ---------------------------------------- 1.1/203.0 MB 12.0 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 1.8/203.0 MB 14.3 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 2.5/203.0 MB 14.5 MB/s eta 0:00:14\n",
      "    --------------------------------------- 3.2/203.0 MB 14.6 MB/s eta 0:00:14\n",
      "    --------------------------------------- 4.1/203.0 MB 15.4 MB/s eta 0:00:13\n",
      "    --------------------------------------- 5.0/203.0 MB 16.1 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 6.0/203.0 MB 16.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 6.9/203.0 MB 16.9 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 7.8/203.0 MB 17.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 8.8/203.0 MB 17.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 9.7/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 10.7/203.0 MB 18.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.5/203.0 MB 18.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 11.6/203.0 MB 17.7 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 12.0/203.0 MB 7.8 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 12.5/203.0 MB 7.7 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 13.3/203.0 MB 7.8 MB/s eta 0:00:25\n",
      "   -- ------------------------------------- 14.3/203.0 MB 7.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 15.4/203.0 MB 7.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 16.2/203.0 MB 7.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 17.1/203.0 MB 7.9 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 18.0/203.0 MB 7.8 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 18.9/203.0 MB 7.8 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 19.9/203.0 MB 7.8 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 20.9/203.0 MB 7.8 MB/s eta 0:00:24\n",
      "   ---- ----------------------------------- 21.9/203.0 MB 19.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 22.8/203.0 MB 20.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 23.7/203.0 MB 20.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 24.4/203.0 MB 19.8 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 25.1/203.0 MB 19.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 25.8/203.0 MB 18.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 26.5/203.0 MB 18.2 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 27.2/203.0 MB 17.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 27.9/203.0 MB 17.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 28.7/203.0 MB 17.7 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 29.4/203.0 MB 17.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 30.1/203.0 MB 16.8 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 30.9/203.0 MB 16.8 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 31.6/203.0 MB 16.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 32.4/203.0 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.2/203.0 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.9/203.0 MB 15.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 34.5/203.0 MB 16.0 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 35.3/203.0 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 36.1/203.0 MB 15.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 36.9/203.0 MB 16.0 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 37.6/203.0 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 38.4/203.0 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 39.1/203.0 MB 16.4 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 39.9/203.0 MB 16.0 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 40.6/203.0 MB 16.0 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 41.3/203.0 MB 16.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 42.0/203.0 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 42.7/203.0 MB 15.6 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 43.3/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 44.0/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 44.7/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 45.5/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 46.2/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 47.0/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 47.6/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 48.3/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 49.0/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 49.8/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 50.5/203.0 MB 15.2 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 51.1/203.0 MB 15.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 51.9/203.0 MB 15.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 52.7/203.0 MB 15.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 53.4/203.0 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 54.1/203.0 MB 15.6 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 55.0/203.0 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 55.9/203.0 MB 16.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 57.0/203.0 MB 16.8 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 58.0/203.0 MB 17.2 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 59.0/203.0 MB 17.7 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 60.2/203.0 MB 18.7 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 61.3/203.0 MB 19.9 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 62.6/203.0 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 63.9/203.0 MB 23.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 65.3/203.0 MB 25.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 66.3/203.0 MB 25.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 67.4/203.0 MB 25.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 68.6/203.0 MB 25.1 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 69.9/203.0 MB 26.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 71.3/203.0 MB 27.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 72.7/203.0 MB 27.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 73.0/203.0 MB 27.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 73.5/203.0 MB 24.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 73.9/203.0 MB 21.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 74.0/203.0 MB 21.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 74.4/203.0 MB 19.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 74.8/203.0 MB 17.7 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 74.9/203.0 MB 17.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 75.2/203.0 MB 15.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 75.4/203.0 MB 14.6 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 76.0/203.0 MB 14.6 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 76.3/203.0 MB 13.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 76.8/203.0 MB 13.1 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 77.3/203.0 MB 12.6 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 77.6/203.0 MB 12.4 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 78.2/203.0 MB 11.9 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 79.1/203.0 MB 11.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 79.3/203.0 MB 11.9 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 79.8/203.0 MB 10.9 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 80.3/203.0 MB 10.7 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 80.8/203.0 MB 10.4 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 81.3/203.0 MB 10.1 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 81.8/203.0 MB 9.6 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.5/203.0 MB 9.5 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 82.8/203.0 MB 9.1 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 83.3/203.0 MB 9.2 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 83.7/203.0 MB 9.1 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 84.6/203.0 MB 9.9 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 84.9/203.0 MB 10.1 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 85.4/203.0 MB 10.6 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 85.9/203.0 MB 10.7 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 86.3/203.0 MB 10.7 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 86.8/203.0 MB 11.1 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 87.3/203.0 MB 10.9 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 87.7/203.0 MB 10.7 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 87.8/203.0 MB 10.4 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 88.7/203.0 MB 10.7 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 89.0/203.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 89.3/203.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 89.8/203.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 90.3/203.0 MB 10.2 MB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 90.8/203.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 91.3/203.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 91.7/203.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 91.9/203.0 MB 9.9 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 92.2/203.0 MB 9.9 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 92.6/203.0 MB 9.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 92.9/203.0 MB 9.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 93.1/203.0 MB 9.5 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 93.6/203.0 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 93.9/203.0 MB 9.2 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 94.9/203.0 MB 9.1 MB/s eta 0:00:12\n",
      "   ------------------ --------------------- 95.7/203.0 MB 9.6 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 96.5/203.0 MB 9.9 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 97.5/203.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 98.5/203.0 MB 11.3 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 99.5/203.0 MB 11.7 MB/s eta 0:00:09\n",
      "   ------------------- ------------------- 100.7/203.0 MB 12.9 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 101.4/203.0 MB 13.4 MB/s eta 0:00:08\n",
      "   ------------------- ------------------- 102.3/203.0 MB 14.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 103.5/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 104.1/203.0 MB 20.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 104.5/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.2/203.0 MB 18.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 105.4/203.0 MB 18.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 105.4/203.0 MB 7.4 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 105.6/203.0 MB 7.3 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 105.8/203.0 MB 7.0 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 106.0/203.0 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 106.5/203.0 MB 6.8 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 106.9/203.0 MB 6.7 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 107.5/203.0 MB 6.6 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 108.2/203.0 MB 6.5 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 108.8/203.0 MB 6.5 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 109.5/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 110.3/203.0 MB 6.4 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 111.0/203.0 MB 6.3 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 111.5/203.0 MB 6.2 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 112.4/203.0 MB 6.2 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 113.1/203.0 MB 6.2 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 113.9/203.0 MB 6.2 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 114.6/203.0 MB 6.3 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 115.5/203.0 MB 6.3 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 116.3/203.0 MB 14.9 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 117.1/203.0 MB 16.0 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 118.0/203.0 MB 16.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 118.7/203.0 MB 16.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 119.5/203.0 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 120.3/203.0 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 121.1/203.0 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 121.9/203.0 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 122.6/203.0 MB 17.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 123.3/203.0 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 124.0/203.0 MB 16.8 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 124.6/203.0 MB 16.4 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 125.0/203.0 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 125.5/203.0 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.0/203.0 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 126.6/203.0 MB 14.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 127.2/203.0 MB 14.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 127.8/203.0 MB 14.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 128.3/203.0 MB 13.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 128.8/203.0 MB 13.6 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 129.4/203.0 MB 13.4 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 129.9/203.0 MB 13.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 130.4/203.0 MB 12.8 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 131.0/203.0 MB 12.6 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 131.5/203.0 MB 12.4 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 132.1/203.0 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 132.6/203.0 MB 12.1 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 133.2/203.0 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 133.7/203.0 MB 11.9 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.3/203.0 MB 11.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.8/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 134.9/203.0 MB 11.5 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 134.9/203.0 MB 6.1 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 135.1/203.0 MB 5.9 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 135.3/203.0 MB 5.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 135.4/203.0 MB 5.7 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 135.6/203.0 MB 5.6 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 136.1/203.0 MB 5.6 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 136.6/203.0 MB 5.5 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 137.0/203.0 MB 5.6 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 137.7/203.0 MB 5.6 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 138.6/203.0 MB 5.6 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 139.6/203.0 MB 5.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 140.6/203.0 MB 6.0 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 141.8/203.0 MB 6.1 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 142.6/203.0 MB 6.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 143.0/203.0 MB 6.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 143.6/203.0 MB 6.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 144.2/203.0 MB 6.2 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 144.8/203.0 MB 6.2 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 145.3/203.0 MB 12.8 MB/s eta 0:00:05\n",
      "   ---------------------------- ---------- 145.8/203.0 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.4/203.0 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 146.9/203.0 MB 14.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 147.4/203.0 MB 15.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.0/203.0 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 148.6/203.0 MB 14.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 149.1/203.0 MB 13.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 149.7/203.0 MB 13.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.2/203.0 MB 13.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.7/203.0 MB 13.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 151.3/203.0 MB 12.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 151.8/203.0 MB 12.1 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 152.4/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 152.6/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 153.2/203.0 MB 11.3 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 154.0/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 154.5/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 155.1/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 155.7/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 156.2/203.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 156.7/203.0 MB 11.7 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 157.0/203.0 MB 11.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 157.4/203.0 MB 6.5 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 158.1/203.0 MB 6.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 158.7/203.0 MB 6.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 159.7/203.0 MB 6.8 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 160.7/203.0 MB 7.0 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 161.8/203.0 MB 7.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 162.8/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 163.4/203.0 MB 7.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 7.4 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 164.0/203.0 MB 5.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 164.6/203.0 MB 5.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 165.4/203.0 MB 5.1 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 166.2/203.0 MB 5.2 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 167.0/203.0 MB 5.3 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 167.8/203.0 MB 8.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 168.4/203.0 MB 8.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 169.1/203.0 MB 8.3 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 169.8/203.0 MB 8.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 170.5/203.0 MB 8.1 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 171.3/203.0 MB 8.0 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 172.1/203.0 MB 7.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 172.8/203.0 MB 7.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 173.4/203.0 MB 7.7 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 173.9/203.0 MB 7.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 174.5/203.0 MB 14.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.0/203.0 MB 14.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 175.6/203.0 MB 14.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.0/203.0 MB 14.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 176.6/203.0 MB 13.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 177.2/203.0 MB 13.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 177.7/203.0 MB 13.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.3/203.0 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 178.9/203.0 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.1/203.0 MB 13.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.5/203.0 MB 12.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 179.6/203.0 MB 12.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 179.6/203.0 MB 6.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.7/203.0 MB 6.0 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.8/203.0 MB 5.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 179.8/203.0 MB 5.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 180.0/203.0 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 180.3/203.0 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 180.7/203.0 MB 5.5 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 181.3/203.0 MB 5.4 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 181.7/203.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 182.4/203.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 183.2/203.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.1/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.7/203.0 MB 5.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 184.9/203.0 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 185.1/203.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 186.0/203.0 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 186.8/203.0 MB 4.6 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 187.7/203.0 MB 4.7 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 188.6/203.0 MB 4.8 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 189.3/203.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 190.0/203.0 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.3/203.0 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 190.4/203.0 MB 5.9 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.0/203.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.9/203.0 MB 6.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 193.2/203.0 MB 6.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 194.3/203.0 MB 6.3 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 195.2/203.0 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 195.9/203.0 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 196.4/203.0 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 197.0/203.0 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 197.6/203.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.1/203.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  198.6/203.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.1/203.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.7/203.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.2/203.0 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.8/203.0 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.3/203.0 MB 14.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  201.9/203.0 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.4/203.0 MB 13.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.8/203.0 MB 13.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.0/203.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.0/203.0 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.0/6.2 MB 29.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.2/6.2 MB 28.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.4/6.2 MB 27.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 26.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 20.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.9/6.2 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
      "   ---------------------------------------- 0.0/926.4 kB ? eta -:--:--\n",
      "   --------------------------------------  921.6/926.4 kB 19.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 926.4/926.4 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB ? eta 0:00:00\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading aiohttp-3.11.10-cp312-cp312-win_amd64.whl (437 kB)\n",
      "   ---------------------------------------- 0.0/437.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 437.4/437.4 kB 28.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 179.6/179.6 kB ? eta 0:00:00\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.1/1.7 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.3/51.3 kB ? eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.1/44.1 kB ? eta 0:00:00\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 90.4/90.4 kB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, tqdm, sympy, propcache, networkx, multidict, fsspec, frozenlist, filelock, aiohappyeyeballs, yarl, torch, lightning-utilities, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.10.0 lightning-utilities-0.11.9 multidict-6.1.0 networkx-3.4.2 propcache-0.2.1 pytorch-lightning-2.4.0 sympy-1.13.1 torch-2.5.1 torchmetrics-1.6.0 tqdm-4.67.1 typing-extensions-4.12.2 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script isympy.exe is installed in 'c:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import cast, List\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "data = pd.read_csv('csv_outputs/cleaned_spotify.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "prediction = 'track_genre'\n",
    "categorical_columns = ['track_name', 'artists', 'album_name', 'track_name']\n",
    "X = data.drop(columns=[prediction, 'track_id', *categorical_columns])\n",
    "y = data[prediction]\n",
    "\n",
    "# one hot encode the y values\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "# Normalize and PCA transform the data\n",
    "X = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_train, X_test, y_train, y_test = cast(\n",
    "    List[pd.DataFrame],\n",
    "    train_test_split(X, y, test_size=0.2, random_state=42)\n",
    ")\n",
    "\n",
    "# PCA transform the data\n",
    "pca_columns = [f'pca_{i}' for i in range(10)]\n",
    "pca = PCA(n_components=10)\n",
    "X_train = pd.DataFrame(\n",
    "    data=pca.fit_transform(X_train),\n",
    "    columns=pca_columns\n",
    ")\n",
    "X_test = pd.DataFrame(\n",
    "    data=pca.transform(X_test),\n",
    "    columns=pca_columns\n",
    ")\n",
    "\n",
    "# Convert the data to tensors\n",
    "X_train = torch.tensor(X_train.to_numpy(np.float32), dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.to_numpy(np.float32), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.to_numpy(np.float32), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.to_numpy(np.float32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([91199, 10]) torch.Size([91199, 114])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n"
     ]
    }
   ],
   "source": [
    "# Check if we have a GPU available\n",
    "print(\"GPU Available: \", torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type   | Params | Mode \n",
      "----------------------------------------\n",
      "0 | fc1  | Linear | 704    | train\n",
      "1 | fc2  | Linear | 4.2 K  | train\n",
      "2 | fc3  | Linear | 65     | train\n",
      "----------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zane Clark\\AppData\\Local\\Temp\\ipykernel_39636\\848849026.py:24: UserWarning: Using a target size (torch.Size([114, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y.view(-1, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 29/91199 [00:00<05:50, 260.30it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zane Clark\\AppData\\Local\\Temp\\ipykernel_39636\\848849026.py:18: UserWarning: Using a target size (torch.Size([114, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(y_hat, y.view(-1, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:  93%|| 85056/91199 [05:52<00:25, 241.03it/s, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\optim\\adam.py:202\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 202\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 17\u001b[0m, in \u001b[0;36mNet.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     16\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 17\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(y_hat, y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[53], line 12\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m---> 12\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m model \u001b[38;5;241m=\u001b[39m Net()\n\u001b[0;32m     32\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zane Clark\\.pyenv\\pyenv-win\\versions\\3.12.0\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "class MetricTracker(pl.Callback):\n",
    "  def __init__(self):\n",
    "    self.collection = []\n",
    "\n",
    "  def on_validation_batch_end(trainer, module, outputs, ...):\n",
    "    vacc = outputs['val_acc'] # you can access them here\n",
    "    self.collection.append(vacc) # track them\n",
    "\n",
    "  def on_validation_epoch_end(trainer, module):\n",
    "    elogs = trainer.logged_metrics # access it here\n",
    "    self.collection.append(elogs)\n",
    "    # do whatever is needed\n",
    "\n",
    "# Define the model\n",
    "class Net(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y.view(-1, 1))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y.view(-1, 1))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "model = Net()\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "trainer.fit(model, train_dataset, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0088],\n",
      "        [0.0088],\n",
      "        [0.0088],\n",
      "        ...,\n",
      "        [0.0088],\n",
      "        [0.0088],\n",
      "        [0.0088]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_hat)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_test)\n\u001b[1;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(y_hat, \u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "# validate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(X_test)\n",
    "    print(y_hat)\n",
    "    print(y_test)\n",
    "    loss = F.mse_loss(test_dataset, y_test.view(-1, 1))\n",
    "model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
